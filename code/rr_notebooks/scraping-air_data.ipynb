{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AirNow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.airnow.gov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AirNow is a government resource about which our group was really excited. We thought that it would be relatively easy to retrieve everything we needed, but it turned out to be more complex than expected. The AirNow API only had RSS feeds for more recent and current data, while all of their historical files were saved in folders and availble to download (link below). Ultimately, we were able to finish the necessary code and successfully download all of the files we wanted, but didn't end up using any of it for a variety of reasons including time constraints and finding another dataset that would provide most of what these files would've given us. There were also some questions about the format and completeness of the AirNow files.\n",
    "\n",
    "The one thing we missed out on by setting these aside was data for Particulate Matter (PM2.5 and PM10), which are both inevitable pollution put out by wildfires, and maybe one of the most important metrics to record when looking at fires and air quality. In retrospect, we really wish we had included in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Airnow Links**\n",
    "\n",
    "API Documentation: https://docs.airnowapi.org  \n",
    "Historical Data Downloads: http://files.airnowtech.org\n",
    "\n",
    "**Data Dictionaries**\n",
    "\n",
    "Daily Data: https://docs.airnowapi.org/docs/DailyDataFactSheet.pdf  \n",
    "Hourly Data: https://docs.airnowapi.org/docs/HourlyDataFactSheet.pdf  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primary Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T04:15:09.359008Z",
     "start_time": "2021-05-22T04:15:08.532478Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import os\n",
    "\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each day contained a large number of files, most of which we didn't need. For the Daily Data, there were two filenames that were used over the years from which the data was collected.\n",
    "\n",
    "- daily_data.dat\n",
    "- daily_data_v2.dat\n",
    "\n",
    "Sample Day:  (may not work without sign-in  \n",
    "http://files.airnowtech.org/?prefix=airnow/2012/20120101/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T04:15:09.365945Z",
     "start_time": "2021-05-22T04:15:09.360662Z"
    }
   },
   "outputs": [],
   "source": [
    "report = []\n",
    "\n",
    "# establish date range\n",
    "start_date = dt.datetime(2013, 10, 22)    # note: daily data files begin 2013-10-22\n",
    "end_date = dt.datetime(2020, 12, 31)\n",
    "delta = dt.timedelta(days=1)\n",
    "\n",
    "# begin loop through date range\n",
    "while start_date <= end_date:\n",
    "    \n",
    "    # create strings of start and end dates\n",
    "    start_string = str(start_date)\n",
    "    end_string = str(end_date)\n",
    "    \n",
    "    # create substrings for year, month, day\n",
    "    year = start_string[0:4]\n",
    "    month = start_string[5:7]\n",
    "    day = start_string[8:10]\n",
    "\n",
    "    # create date string to add to URL\n",
    "    date_string = f'{year}/{year}{month}{day}/'\n",
    "\n",
    "    # loop through two possible filenames\n",
    "    for file in ['daily_data.dat', 'daily_data_v2.dat']:     \n",
    "            \n",
    "        try:\n",
    "            # set full url for data file\n",
    "            data_url = f' https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow/{date_string}{file}'\n",
    "\n",
    "            # get request for each day's data file\n",
    "            r = requests.get(data_url)\n",
    "            \n",
    "            # Check URL connection status\n",
    "            if r.status_code == 200:\n",
    "                \n",
    "                # find or create destination folder\n",
    "                file_path = f\"data/{file}\"\n",
    "                directory = os.path.dirname(file_path)\n",
    "                if not os.path.exists(directory):\n",
    "                    os.makedirs(directory)       \n",
    "\n",
    "                # write file to destination\n",
    "                with open(f'data/{date_string[5:-1]}{file}','a') as f:\n",
    "                    f.write(r.text)\n",
    "                \n",
    "                # add logging info for successful download to report list\n",
    "                cur_datetime = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                report.append({'event': f'Data saved successfully',\n",
    "                               'date': f'{year}-{month}-{day}',\n",
    "                               'file': f'{file}',\n",
    "                               'datetime': f'{cur_datetime}',\n",
    "                               'exception': ''\n",
    "                               })\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        # if error is raised above, add logging info for failed download to report list\n",
    "        except Exception as e:\n",
    "            cur_datetime = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f'{cur_datetime}: {e}')\n",
    "            report.append({'event': f'Could not save data',\n",
    "                           'date': f'{year}-{month}-{day}',\n",
    "                           'file': f'{file}',\n",
    "                           'datetime': f'{cur_datetime}',\n",
    "                           'exception': f'{e}'\n",
    "                           })            \n",
    "            \n",
    "        # sleep for the sake of the server and output the report csv after every file download attempt    \n",
    "        time.sleep(.25)            \n",
    "        df_report = pd.DataFrame(report)\n",
    "        df_report.to_csv(f'report.csv', index=False)    \n",
    "    \n",
    "    # advance current position in date range by delta set at the top\n",
    "    start_date += delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had we decided to use the data, our first step would have been to convert the `.dat` files into `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T04:15:09.373930Z",
     "start_time": "2021-05-22T04:15:09.368217Z"
    }
   },
   "outputs": [],
   "source": [
    "file_test = '/Users/rileydrobertson/DSI/projects/project_5/AirQuality-USWest/data/air_now/data_airnow_daily/20131022daily_data.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T04:15:09.407759Z",
     "start_time": "2021-05-22T04:15:09.376177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>000020301</td>\n",
       "      <td>WELLINGTON</td>\n",
       "      <td>PM2.5-24hr</td>\n",
       "      <td>UG/M3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Environment Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>000020301</td>\n",
       "      <td>WELLINGTON</td>\n",
       "      <td>OZONE-1HR</td>\n",
       "      <td>PPB</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Environment Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>000020301</td>\n",
       "      <td>WELLINGTON</td>\n",
       "      <td>OZONE-8HR</td>\n",
       "      <td>PPB</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Environment Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>000030118</td>\n",
       "      <td>HALIFAX</td>\n",
       "      <td>OZONE-8HR</td>\n",
       "      <td>PPB</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Environment Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>000030118</td>\n",
       "      <td>HALIFAX</td>\n",
       "      <td>OZONE-1HR</td>\n",
       "      <td>PPB</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Environment Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>371230001</td>\n",
       "      <td>Candor FRO</td>\n",
       "      <td>PM2.5-24hr</td>\n",
       "      <td>UG/M3</td>\n",
       "      <td>15.7</td>\n",
       "      <td>24</td>\n",
       "      <td>North Carolina DENR - Divison of Air Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>480271045</td>\n",
       "      <td>Temple Georgia C1045</td>\n",
       "      <td>OZONE-1HR</td>\n",
       "      <td>PPB</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Texas Commission on Environmental Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>480271045</td>\n",
       "      <td>Temple Georgia C1045</td>\n",
       "      <td>OZONE-8HR</td>\n",
       "      <td>PPB</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Texas Commission on Environmental Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>484690609</td>\n",
       "      <td>Inez C609</td>\n",
       "      <td>OZONE-8HR</td>\n",
       "      <td>PPB</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Texas Commission on Environmental Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>10/22/13</td>\n",
       "      <td>484690609</td>\n",
       "      <td>Inez C609</td>\n",
       "      <td>OZONE-1HR</td>\n",
       "      <td>PPB</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Texas Commission on Environmental Quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3680 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1                     2           3      4     5   6  \\\n",
       "0     10/22/13  000020301            WELLINGTON  PM2.5-24hr  UG/M3  13.0  24   \n",
       "1     10/22/13  000020301            WELLINGTON   OZONE-1HR    PPB  37.0   1   \n",
       "2     10/22/13  000020301            WELLINGTON   OZONE-8HR    PPB  33.0   8   \n",
       "3     10/22/13  000030118               HALIFAX   OZONE-8HR    PPB  35.0   8   \n",
       "4     10/22/13  000030118               HALIFAX   OZONE-1HR    PPB  38.0   1   \n",
       "...        ...        ...                   ...         ...    ...   ...  ..   \n",
       "3675  10/22/13  371230001            Candor FRO  PM2.5-24hr  UG/M3  15.7  24   \n",
       "3676  10/22/13  480271045  Temple Georgia C1045   OZONE-1HR    PPB  46.0   1   \n",
       "3677  10/22/13  480271045  Temple Georgia C1045   OZONE-8HR    PPB  41.0   8   \n",
       "3678  10/22/13  484690609             Inez C609   OZONE-8HR    PPB  43.0   8   \n",
       "3679  10/22/13  484690609             Inez C609   OZONE-1HR    PPB  47.0   1   \n",
       "\n",
       "                                                 7  \n",
       "0                               Environment Canada  \n",
       "1                               Environment Canada  \n",
       "2                               Environment Canada  \n",
       "3                               Environment Canada  \n",
       "4                               Environment Canada  \n",
       "...                                            ...  \n",
       "3675  North Carolina DENR - Divison of Air Quality  \n",
       "3676     Texas Commission on Environmental Quality  \n",
       "3677     Texas Commission on Environmental Quality  \n",
       "3678     Texas Commission on Environmental Quality  \n",
       "3679     Texas Commission on Environmental Quality  \n",
       "\n",
       "[3680 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file_test, sep='|', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T04:15:09.412699Z",
     "start_time": "2021-05-22T04:15:09.409421Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = []\n",
    "\n",
    "# establish date range\n",
    "start_date = dt.datetime(2014, 1, 1)    # daily data files begin 2013-10-22\n",
    "end_date = dt.datetime(2019, 12, 31)\n",
    "delta = dt.timedelta(days=1)\n",
    "\n",
    "# begin loop through date range\n",
    "while start_date <= end_date:\n",
    "    \n",
    "    # create strings of start and end dates\n",
    "    start_string = str(start_date)\n",
    "    end_string = str(end_date)\n",
    "    \n",
    "    # create substrings for year, month, day\n",
    "    year = start_string[0:4]\n",
    "    month = start_string[5:7]\n",
    "    day = start_string[8:10]\n",
    "\n",
    "    # create filepath string\n",
    "    date_string = f'{year}/{year}{month}{day}/'\n",
    "    \n",
    "    \n",
    "    # print on-screen updates at the first of every month\n",
    "    if day == '01':\n",
    "        cur_datetime = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f'Collecting files for {month}-{year}...')   \n",
    "    \n",
    "\n",
    "    # loop through files for midnight, 6am, noon, and 6pm\n",
    "    for file in [f'HourlyData_{year}{month}{day}00.dat', # midnight 1 \n",
    "                 f'HourlyData_{year}{month}{day}06.dat',\n",
    "                 f'HourlyData_{year}{month}{day}12.dat',\n",
    "                 f'HourlyData_{year}{month}{day}18.dat',\n",
    "                 f'HourlyData_{year}{month}{day}24.dat']: # midnight 2\n",
    "         \n",
    "            \n",
    "        try:\n",
    "            # set full url for data file\n",
    "            data_url = f'https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow/{date_string}{file}'\n",
    "\n",
    "            # get request for each day's data files\n",
    "            r = requests.get(data_url)\n",
    "            \n",
    "            # Check URL connection status\n",
    "            if r.status_code == 200:\n",
    "                \n",
    "                # find or create destination folder\n",
    "                file_path = f\"data/{file}\"\n",
    "                directory = os.path.dirname(file_path)\n",
    "\n",
    "                if not os.path.exists(directory):\n",
    "                    os.makedirs(directory)       \n",
    "\n",
    "                # write file to destination\n",
    "                with open(f'data/{date_string[5:-1]}{file}','a') as f:\n",
    "                    f.write(r.text)\n",
    "                \n",
    "                # add logging info for successful download to report list\n",
    "                cur_datetime = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                report.append({'event': f'Data saved successfully',\n",
    "                               'date': f'{year}-{month}-{day}',\n",
    "                               'file': f'{file}',\n",
    "                               'timestamp': f'{cur_datetime}',\n",
    "                               'exception': ''\n",
    "                               })\n",
    "            # if status code is not good, add logging info for failed download to report list    \n",
    "            else:\n",
    "                cur_datetime = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                report.append({'event': f'Could not save data',\n",
    "                               'date': f'{year}-{month}-{day}',\n",
    "                               'file': f'{file}',\n",
    "                               'timestamp': f'{cur_datetime}',\n",
    "                               'exception': 'Error: Status Code'\n",
    "                               })    \n",
    "        # if error is raised above, add logging info for failed download to report list\n",
    "        except Exception as e:\n",
    "            cur_datetime = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f'{cur_datetime}: {e}')\n",
    "            report.append({'event': f'Could not save data',\n",
    "                           'date': f'{year}-{month}-{day}',\n",
    "                           'file': f'{file}',\n",
    "                           'timestamp': f'{cur_datetime}',\n",
    "                           'exception': f'{e}'\n",
    "                           })            \n",
    "            \n",
    "        # sleep for the sake of the server and output the report csv after every file download attempt    \n",
    "        time.sleep(.25)            \n",
    "        df_report = pd.DataFrame(report)\n",
    "        df_report.to_csv(f'airnow_scrape_hourly_report.csv', index=False)    \n",
    "\n",
    "    # advance current position in date range by delta set at the top    \n",
    "    start_date += delta\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
